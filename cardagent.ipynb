{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aimkeys-Sir/Aimkeys-sir/blob/main/cardagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import collections\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from typing import Type\n",
        "\n",
        "\n",
        "class CardAgent(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.first_layer = params[\"first_layer_size\"]\n",
        "        self.second_layer = params[\"second_layer_size\"]\n",
        "        self.third_layer = params[\"third_layer_size\"]\n",
        "        self.gamma = params[\"gamma\"]\n",
        "        self.learning_rate = params[\"learning_rate\"]\n",
        "        self.memory = collections.deque(maxlen= params[\"memory_size\"])\n",
        "        self.batch_size = params[\"batch_size\"]\n",
        "        self.weights_path = params[\"weights_path\"]\n",
        "        self.optimizer = None\n",
        "        self.load_weights = params[\"load_weights\"]\n",
        "        self.mask = None\n",
        "        self.network()\n",
        "\n",
        "    def network(self):\n",
        "        self.requires_grad_ = False\n",
        "        self.fc1 = nn.Linear(57, self.first_layer)\n",
        "        self.fc2 = nn.Linear(self.first_layer, self.second_layer)\n",
        "        self.fc3 = nn.Linear(self.second_layer, self.third_layer)\n",
        "        self.fc4 = nn.Linear(self.third_layer, 60)\n",
        "\n",
        "        if not self.load_weights:\n",
        "           self.model = self.load_state_dict(torch.load(self.weights_path))\n",
        "           print(\"weights loaded\")\n",
        "\n",
        "\n",
        "    def forward(self, observation):\n",
        "        x = F.relu(self.fc1(observation))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.softmax(self.fc4(x), dim=-1)\n",
        "\n",
        "        if self.mask != None:\n",
        "          return x * self.mask\n",
        "        return x\n",
        "\n",
        "    def remember(self, observation, move, reward, next_state, complete):\n",
        "        self.memory.append((observation, move, reward, next_state, complete))\n",
        "\n",
        "    def train_memory(self, observation, move, reward, next_state, complete):\n",
        "        self.train()\n",
        "        self.mask = None\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "        target = reward\n",
        "\n",
        "        state_tensor = torch.tensor(np.expand_dims(observation, 0), dtype=torch.float32, requires_grad=True)\n",
        "        next_state_tensor = torch.tensor(np.expand_dims(observation, 0), dtype=torch.float32, requires_grad = True)\n",
        "\n",
        "        if not complete:\n",
        "            target = reward + self.gamma * torch.max(self.forward(next_state_tensor[0]))\n",
        "\n",
        "        output = self.forward(state_tensor)\n",
        "        try:\n",
        "          target_f = output.clone()\n",
        "          if target_f.shape == torch.Size([1,1,60]) :\n",
        "            output = output[0]\n",
        "            target_f = target_f[0]\n",
        "          target_f[0][np.argmax(move)] = target\n",
        "          target_f.detach()\n",
        "          self.optimizer.zero_grad()\n",
        "          loss = F.mse_loss(output, target_f)\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "        except IndexError:\n",
        "          print(output.shape)\n",
        "          print(move)\n",
        "          raise ValueError(\"what is this?\")\n",
        "\n",
        "\n",
        "    def replay_exp(self):\n",
        "        if len(self.memory) > self.batch_size:\n",
        "            minibatch = random.sample(self.memory, self.batch_size)\n",
        "        else:\n",
        "            minibatch = self.memory\n",
        "\n",
        "        for observation, move, reward, next_state, complete in minibatch:\n",
        "            self.train_memory(observation, move, reward, next_state, complete)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T08:12:24.130610Z",
          "iopub.execute_input": "2023-06-26T08:12:24.131072Z",
          "iopub.status.idle": "2023-06-26T08:12:24.153216Z",
          "shell.execute_reply.started": "2023-06-26T08:12:24.131037Z",
          "shell.execute_reply": "2023-06-26T08:12:24.151962Z"
        },
        "trusted": true,
        "id": "kxRSMTDHzoOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cs =  [\n",
        "  \"ace_of_clubs\",\n",
        "  \"ace_of_spades\",\n",
        "  \"ace_of_hearts\",\n",
        "  \"ace_of_diamonds\",\n",
        "  \"2_of_clubs\",\n",
        "  \"2_of_spades\",\n",
        "  \"2_of_hearts\",\n",
        "  \"2_of_diamonds\",\n",
        "  \"3_of_clubs\",\n",
        "  \"3_of_spades\",\n",
        "  \"3_of_hearts\",\n",
        "  \"3_of_diamonds\",\n",
        "  \"4_of_clubs\",\n",
        "  \"4_of_spades\",\n",
        "  \"4_of_hearts\",\n",
        "  \"4_of_diamonds\",\n",
        "  \"5_of_clubs\",\n",
        "  \"5_of_spades\",\n",
        "  \"5_of_hearts\",\n",
        "  \"5_of_diamonds\",\n",
        "  \"6_of_clubs\",\n",
        "  \"6_of_spades\",\n",
        "  \"6_of_hearts\",\n",
        "  \"6_of_diamonds\",\n",
        "  \"7_of_clubs\",\n",
        "  \"7_of_spades\",\n",
        "  \"7_of_hearts\",\n",
        "  \"7_of_diamonds\",\n",
        "  \"8_of_clubs\",\n",
        "  \"8_of_spades\",\n",
        "  \"8_of_hearts\",\n",
        "  \"8_of_diamonds\",\n",
        "  \"9_of_clubs\",\n",
        "  \"9_of_spades\",\n",
        "  \"9_of_hearts\",\n",
        "  \"9_of_diamonds\",\n",
        "  \"10_of_clubs\",\n",
        "  \"10_of_spades\",\n",
        "  \"10_of_hearts\",\n",
        "  \"10_of_diamonds\",\n",
        "  \"jack_of_clubs\",\n",
        "  \"jack_of_spades\",\n",
        "  \"jack_of_hearts\",\n",
        "  \"jack_of_diamonds\",\n",
        "  \"queen_of_clubs\",\n",
        "  \"queen_of_spades\",\n",
        "  \"queen_of_hearts\",\n",
        "  \"queen_of_diamonds\",\n",
        "  \"king_of_clubs\",\n",
        "  \"king_of_spades\",\n",
        "  \"king_of_hearts\",\n",
        "  \"king_of_diamonds\",\n",
        "  \"black_joker\",\n",
        "  \"red_joker\",\n",
        "  \"choose clubs\",\n",
        "  \"choose spades\",\n",
        "  \"choose diamonds\",\n",
        "  \"choose hearts\",\n",
        "  \"complete build\",\n",
        "  \"pick card\"\n",
        "]\n",
        "\n",
        "params = dict()\n",
        "\n",
        "params[\"first_layer_size\"] = 1024\n",
        "params[\"second_layer_size\"] = 512\n",
        "params[\"third_layer_size\"] = 256\n",
        "params[\"learning_rate\"] = 0.01\n",
        "params[\"memory_size\"] = 12500\n",
        "params[\"load_weights\"] = False\n",
        "params['train'] = True\n",
        "params[\"epsilon_decay_linear\"] = 0.1\n",
        "params[\"episodes\"] = 5\n",
        "params[\"batch_size\"] = 1000\n",
        "params[\"gamma\"] = 0.99\n",
        "\n",
        "\n",
        "params1 = params.copy()\n",
        "params2 = params.copy()\n",
        "\n",
        "params1[\"weights_path\"] = \"weights/agent1/weights.h5\"\n",
        "params1[\"load_weights\"] = True\n",
        "params1[\"train\"] = False\n",
        "\n",
        "\n",
        "params2[\"weights_path\"] = \"weights/agent2/weights.h5\"\n",
        "\n",
        "questions = [28, 29, 30, 31, 51, 50, 49, 48, 47, 46, 45, 44]\n",
        "aces = [0, 1, 2, 3]\n",
        "punishers = [4, 5, 6, 7, 8, 9, 10, 11, 52, 53]\n",
        "all_cards_without_jokers = list(range(52))\n",
        "\n",
        "def to_cs(n_l):\n",
        "    h = []\n",
        "    for n in n_l:\n",
        "        h.append(cs[n])\n",
        "    return h\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T08:12:36.710107Z",
          "iopub.execute_input": "2023-06-26T08:12:36.710507Z",
          "iopub.status.idle": "2023-06-26T08:12:36.726269Z",
          "shell.execute_reply.started": "2023-06-26T08:12:36.710477Z",
          "shell.execute_reply": "2023-06-26T08:12:36.725152Z"
        },
        "trusted": true,
        "id": "RACYW4Y4zoOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Player():\n",
        "    def __init__(self, game, index) -> None:\n",
        "        self.hand = []\n",
        "        self.build = []\n",
        "        self.game = game\n",
        "        self.asking = False\n",
        "        self.index = index\n",
        "        self.reward = 0\n",
        "        self.won = 0\n",
        "        self.agent = None\n",
        "\n",
        "    def can_complete(self):\n",
        "        if len(self.build) == 0 or self.build[-1] in questions:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "    def check_in_white(self):\n",
        "         return [card for card in self.hand if card in self.game.white_list(build=self.build)]\n",
        "\n",
        "    def waste_card(self, card):\n",
        "        white = self.game.white_list(build=self.build)\n",
        "        if card in white:\n",
        "            self.build += [card]\n",
        "            # print(f\"build:{ self.build} card: {card}\")\n",
        "            self.hand = list(filter(lambda x: x != card, self.hand))\n",
        "            self.reward = 1\n",
        "        else:\n",
        "            # print(f\"build:{ self.build} card: {card}\")\n",
        "            self.reward = -1\n",
        "            # wrong move\n",
        "\n",
        "    def pick_cards(self):\n",
        "        self.game.pick(player=self)\n",
        "        self.game.new_turn()\n",
        "        self.build.clear()\n",
        "        self.reward = ((len(self.hand)-4) / 2) * - \\\n",
        "            1 if len(self.hand) > 6 else 0\n",
        "\n",
        "    def complete_build(self):\n",
        "        if len(self.build) == 0:\n",
        "            self.reward = -1\n",
        "            return\n",
        "\n",
        "        self.game.waste(self)\n",
        "\n",
        "        if len(self.hand) == 0 and self.build[-1] not in questions + aces + punishers and len(self.game.card_less) == 0:\n",
        "            self.reward = 10\n",
        "            self.game.complete = True\n",
        "            self.game.winner = self.index\n",
        "            self.won +=1\n",
        "            self.build = []\n",
        "            return\n",
        "        elif len(self.hand) == 0 and (self.build[-1] in questions+aces+punishers or len(self.game.card_less)>0):\n",
        "            self.game.card_less += [self.index]\n",
        "\n",
        "        self.build.clear()\n",
        "        self.reward = 3\n",
        "        if not self.asking:\n",
        "            self.game.new_turn()\n",
        "\n",
        "    def choose_flower(self, flower):\n",
        "        if self.asking:\n",
        "            self.game.action = flower\n",
        "            self.game.new_turn()\n",
        "            self.asking = False\n",
        "        else:\n",
        "            self.reward = -1\n",
        "\n",
        "    def do_move(self, move):\n",
        "        self.reward = 0\n",
        "        if move < 54:\n",
        "            self.waste_card(move)\n",
        "        elif move > 53 and move < 58:\n",
        "            self.choose_flower(move-54)\n",
        "        elif move == 58:\n",
        "            self.complete_build()\n",
        "        elif move == 59:\n",
        "            self.pick_cards()\n",
        "\n",
        "    def one_hot_encoded_hand(self):\n",
        "        try:\n",
        "            tensor = torch.zeros(54)\n",
        "            tensor[self.hand] = 1.0\n",
        "            return tensor\n",
        "        except IndexError:\n",
        "            print(self.hand, self.game.deck)\n",
        "            raise ValueError(\"happened again\")\n",
        "\n",
        "    def observation(self):\n",
        "        top = self.build[-1] if len(self.build)> 0 else self.game.top_card\n",
        "        top_normal = top / 53\n",
        "\n",
        "        actions = 0 if self.game.action == -1 else self.game.action + 1\n",
        "        actions_normal = actions / 8\n",
        "        cardless = 1 if len(self.game.card_less) > 0 else 0\n",
        "\n",
        "        return torch.cat([self.one_hot_encoded_hand(), torch.tensor([top_normal, actions_normal, cardless], requires_grad = False)], dim=0)\n",
        "\n",
        "    def mask(self):\n",
        "        white = self.game.white_list(build = self.build)\n",
        "        match = []\n",
        "        for card in self.hand:\n",
        "            if card in white:\n",
        "                match.append(card)\n",
        "\n",
        "        complete = 1 if self.can_complete() else 0\n",
        "        can_pick = 0 if (len(self.build)>0 and self.build[-1] not in questions) else 1\n",
        "\n",
        "        if self.asking:\n",
        "            return torch.cat([torch.zeros(54),torch.tensor([1,1,1,1], requires_grad=False), torch.zeros(2)])\n",
        "        else:\n",
        "            match_t = torch.zeros(58)\n",
        "            match_t[match] = 1.0\n",
        "\n",
        "            return torch.cat([match_t, torch.tensor([complete, can_pick], requires_grad= False)], dim=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T08:12:41.659433Z",
          "iopub.execute_input": "2023-06-26T08:12:41.659819Z",
          "iopub.status.idle": "2023-06-26T08:12:41.688858Z",
          "shell.execute_reply.started": "2023-06-26T08:12:41.659790Z",
          "shell.execute_reply": "2023-06-26T08:12:41.687550Z"
        },
        "trusted": true,
        "id": "pxlQtbHQzoOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Game():\n",
        "    def __init__(self) -> None:\n",
        "        self.complete = True\n",
        "        self.wastes = []\n",
        "        self.deck = []\n",
        "        self.top_card = None\n",
        "        self.action = -1     # -1 - no action, 0-3 pattern(clubs, spades, diamonds, hearts), 4-6 punishers(pick 2,3,5), 7- jump\n",
        "        self.turn = 0\n",
        "        self.card_less = []\n",
        "        self.winner = None\n",
        "\n",
        "    def new_turn(self):\n",
        "        self.turn = (self.turn+1) % 2\n",
        "\n",
        "    def waste(self, player):\n",
        "        self.action = -1\n",
        "        top = player.build[-1]\n",
        "        if self.action > 3 and top < 4:\n",
        "            aces_in_build = list(filter(lambda x: x < 4, player.build))\n",
        "\n",
        "            if len(aces_in_build) < 2:\n",
        "                top = self.wastes[-1]\n",
        "                self.turn = (self.turn+1) % 2\n",
        "                self.wastes = self.wastes[0:-1] + \\\n",
        "                    player.build + self.wastes[-1:]\n",
        "            else:\n",
        "                player.asking = True\n",
        "        elif top < 4:\n",
        "            player.asking = True\n",
        "            self.wastes += player.build\n",
        "        else:\n",
        "            self.wastes += player.build\n",
        "\n",
        "        self.top_card = self.wastes[-1]\n",
        "\n",
        "        if self.top_card in punishers:\n",
        "            if math.floor(self.top_card/4) == 2:\n",
        "                self.action = 4\n",
        "            elif math.floor(self.top_card/4) == 3:\n",
        "                self.action = 5\n",
        "            elif self.top_card in [52, 53]:\n",
        "                self.action = 6\n",
        "\n",
        "    def pick(self, player):\n",
        "        pick_num = 1\n",
        "        if self.action == 4:\n",
        "            pick_num = 2\n",
        "            self.action = -1\n",
        "        elif self.action == 5:\n",
        "            pick_num = 3\n",
        "            self.action = -1\n",
        "        elif self.action == 6:\n",
        "            pick_num = 5\n",
        "            self.action = -1\n",
        "\n",
        "        #if there's not enough cards on deck, reshuffle\n",
        "        if len(self.deck) < pick_num:\n",
        "            self.deck += self.wastes[0:-1]\n",
        "            self.wastes = self.wastes[-1:]\n",
        "            self.top_card = self.wastes[-1]\n",
        "\n",
        "        picked_cards = random.sample(self.deck, pick_num)\n",
        "        self.deck = list(filter(lambda x: x not in picked_cards, self.deck))\n",
        "\n",
        "        player.hand += picked_cards\n",
        "\n",
        "        #if the player was cardless, remove them from card_less list\n",
        "        if player.index in self.card_less:\n",
        "            self.card_less = list(filter(lambda x: x != player.index, self.card_less))\n",
        "\n",
        "    def white_list(self, build=[]):\n",
        "        if self.action != -1:\n",
        "            if self.action < 4:\n",
        "                white = list(filter(lambda x: x %\n",
        "                             4 == self.action, all_cards_without_jokers))\n",
        "                if self.action < 2:\n",
        "                    white += [52]\n",
        "                else:\n",
        "                    white += [53]\n",
        "                return white + aces\n",
        "            elif self.action == 4:\n",
        "                return [4, 5, 6, 7] + aces\n",
        "            elif self.action == 5:\n",
        "                return [8, 9, 10, 11] + aces\n",
        "            elif self.action == 6:\n",
        "                return [52, 53] + aces\n",
        "            elif self.action == 7:\n",
        "                return list(filter(lambda x: math.floor(x/4) == 10, all_cards_without_jokers))\n",
        "\n",
        "        if len(build) == 0:\n",
        "            if self.top_card == 52:\n",
        "                white = list(filter(lambda x: x %\n",
        "                             4 < 2, all_cards_without_jokers))\n",
        "                white += aces + [52, 53]\n",
        "            elif self.top_card == 53:\n",
        "                white = list(filter(lambda x: x %\n",
        "                             4 > 1, all_cards_without_jokers))\n",
        "                white += aces + [52, 53]\n",
        "            else:\n",
        "                white = list(filter(lambda x: x % 4 == self.top_card % 4 or math.floor(\n",
        "                    x/4) == math.floor(self.top_card/4), all_cards_without_jokers))\n",
        "                if self.top_card % 4 < 2:\n",
        "                    white += [52]\n",
        "                else:\n",
        "                    white += [53]\n",
        "            return white\n",
        "        else:\n",
        "            last = build[-1]\n",
        "            if last in questions:\n",
        "                white = list(filter(lambda x: x % 4 == last % 4 or math.floor(\n",
        "                    x/4) == math.floor(last/4), all_cards_without_jokers))\n",
        "                if self.top_card % 4 < 2:\n",
        "                    white += [52]\n",
        "                else:\n",
        "                    white += [53]\n",
        "                return white + aces\n",
        "            elif last == 52 or last == 53:\n",
        "                return [52, 53]\n",
        "            else:\n",
        "                white = list(filter(lambda x: math.floor(\n",
        "                    x/4) == math.floor(last/4), all_cards_without_jokers))\n",
        "                return white\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T08:12:46.631184Z",
          "iopub.execute_input": "2023-06-26T08:12:46.631644Z",
          "iopub.status.idle": "2023-06-26T08:12:46.667564Z",
          "shell.execute_reply.started": "2023-06-26T08:12:46.631606Z",
          "shell.execute_reply": "2023-06-26T08:12:46.665985Z"
        },
        "trusted": true,
        "id": "fGnth5bazoOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_game(game, players):\n",
        "    game.deck = list(range(54))\n",
        "\n",
        "    for player in players:\n",
        "        player.hand = random.sample(game.deck, 4)\n",
        "\n",
        "        game.deck = list(filter(lambda x: x not in player.hand, game.deck))\n",
        "\n",
        "    poss_top = list(\n",
        "        filter(lambda x: x not in questions+aces+punishers, game.deck))\n",
        "    game.top_card = random.choice(poss_top)\n",
        "    game.wastes.append(game.top_card)\n",
        "\n",
        "    game.deck = list(filter(lambda x: x != game.top_card, game.deck))\n",
        "    game.winner = None\n",
        "    game.complete = False\n",
        "\n",
        "\n",
        "game = Game()\n",
        "player1 = Player(game=game, index=0)\n",
        "player2 = Player(game=game, index=1)\n",
        "\n",
        "def play(player, agent):\n",
        "    state = player.observation()\n",
        "    print(f\"\\nplayer {player.index+1}\")\n",
        "    if random.uniform(0,1) < agent.epsilon:\n",
        "        prediction = torch.rand(60)\n",
        "        prediction = prediction * player.mask()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            state = torch.tensor(np.expand_dims(state, 0), dtype=torch.float32, requires_grad=False)\n",
        "            agent.mask = player.mask()\n",
        "            prediction = agent(state)\n",
        "            print(f\"agentPred: {prediction}\")\n",
        "\n",
        "    move = np.argmax(prediction).cpu().detach().numpy().item()\n",
        "\n",
        "    print(f\"move: {move}:{to_cs([move])}\")\n",
        "\n",
        "    player.do_move(move)\n",
        "    print(f\"reward: {player.reward}\")\n",
        "\n",
        "    next_state = player.observation()\n",
        "    m = np.eye(60)[np.argmax(prediction).numpy()]\n",
        "\n",
        "    agent.remember(observation=state, move=m, reward=player.reward, next_state=next_state, complete=player.game.complete)\n",
        "\n",
        "def run():\n",
        "    agent1 = CardAgent(params=params1)\n",
        "    agent1.optimizer = optim.Adam(\n",
        "        agent1.parameters(), weight_decay=0, lr=params1['learning_rate'])\n",
        "    agent2 = CardAgent(params=params2)\n",
        "    agent2.optimizer = optim.Adam(\n",
        "        agent2.parameters(), weight_decay=0, lr=params2['learning_rate'])\n",
        "    games_count = 0\n",
        "    steps = 0\n",
        "\n",
        "    player1.agent = agent1\n",
        "    player2.agent = agent2\n",
        "\n",
        "    def replay(agent):\n",
        "        agent.replay_exp()\n",
        "        model_weights = agent.state_dict()\n",
        "        torch.save(model_weights, agent.weights_path)\n",
        "\n",
        "    while games_count < params['episodes']:\n",
        "        if game.complete:\n",
        "            steps = 0\n",
        "            initialize_game(game=game, players=[player1, player2])\n",
        "            print(\"\\nhands\")\n",
        "\n",
        "            print(to_cs(player1.hand))\n",
        "            print(to_cs(player2.hand))\n",
        "\n",
        "            print(\"\\n top card\")\n",
        "            print(cs[game.top_card])\n",
        "\n",
        "        while not game.complete:\n",
        "            if game.turn == 0:\n",
        "                if not params1['train']:\n",
        "                    agent1.epsilon = 0.01\n",
        "                else:\n",
        "                    agent1.epsilon = 1 - (games_count * params1[\"epsilon_decay_linear\"])\n",
        "\n",
        "                play(player=player1, agent=agent1)\n",
        "            elif game.turn == 1:\n",
        "                if not params2['train']:\n",
        "                    agent2.epsilon = 0.01\n",
        "                else:\n",
        "                    agent2.epsilon = 1 - \\\n",
        "                        (games_count * params1[\"epsilon_decay_linear\"])\n",
        "                play(player=player2, agent=agent2)\n",
        "\n",
        "\n",
        "            print(f\"game: {games_count}.  step: {steps} turn: {game.turn} score: {player1.won} - {player2.won}\")\n",
        "            steps += 1\n",
        "            if steps>1000:\n",
        "                game.complete = True\n",
        "            if game.complete:\n",
        "              if game.winner:\n",
        "                for p in [player1, player2] :\n",
        "                  if p.index != game.winner:\n",
        "                    p.reward = -10\n",
        "                    state = p.observation()\n",
        "                    m = np.eye(60)\n",
        "                    p.agent.remember(observation=state, move=m, reward=p.reward, next_state=state, complete=p.game.complete)\n",
        "\n",
        "              games_count += 1\n",
        "              replay(agent=agent1)\n",
        "              replay(agent=agent2)\n",
        "\n",
        "\n",
        "\n",
        "run()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-26T08:12:52.530137Z",
          "iopub.execute_input": "2023-06-26T08:12:52.530579Z",
          "iopub.status.idle": "2023-06-26T08:12:52.772254Z",
          "shell.execute_reply.started": "2023-06-26T08:12:52.530547Z",
          "shell.execute_reply": "2023-06-26T08:12:52.770400Z"
        },
        "trusted": true,
        "id": "MIvdIqAGzoOv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}